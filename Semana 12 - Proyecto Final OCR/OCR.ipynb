{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YponT9XTPGdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pVqwDnYaa6r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_principal = \"/content/drive/MyDrive/IronHack/Proyecto/\" # Albert"
      ],
      "metadata": {
        "id": "go5j9IIxPMiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyVkIWobPC3Y"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('ucaslcl/GOT-OCR2_0', trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained('ucaslcl/GOT-OCR2_0', trust_remote_code=True, low_cpu_mem_usage=True, device_map='cuda', use_safetensors=True, pad_token_id=tokenizer.eos_token_id)\n",
        "model = model.eval().cuda()\n",
        "\n",
        "\n",
        "# input your test image\n",
        "image_file = 'xxx.jpg'\n",
        "\n",
        "# plain texts OCR\n",
        "res = model.chat(tokenizer, image_file, ocr_type='ocr')\n",
        "\n",
        "# format texts OCR:\n",
        "# res = model.chat(tokenizer, image_file, ocr_type='format')\n",
        "\n",
        "# fine-grained OCR:\n",
        "# res = model.chat(tokenizer, image_file, ocr_type='ocr', ocr_box='')\n",
        "# res = model.chat(tokenizer, image_file, ocr_type='format', ocr_box='')\n",
        "# res = model.chat(tokenizer, image_file, ocr_type='ocr', ocr_color='')\n",
        "# res = model.chat(tokenizer, image_file, ocr_type='format', ocr_color='')\n",
        "\n",
        "# multi-crop OCR:\n",
        "# res = model.chat_crop(tokenizer, image_file, ocr_type='ocr')\n",
        "# res = model.chat_crop(tokenizer, image_file, ocr_type='format')\n",
        "\n",
        "# render the formatted OCR results:\n",
        "# res = model.chat(tokenizer, image_file, ocr_type='format', render=True, save_render_file = './demo.html')\n",
        "\n",
        "print(res)\n"
      ]
    }
  ]
}